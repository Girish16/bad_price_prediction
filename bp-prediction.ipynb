{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":90274,"databundleVersionId":10995111,"sourceType":"competition"}],"dockerImageVersionId":30839,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"source":"<a href=\"https://www.kaggle.com/code/girishkalyan/bp-prediction?scriptVersionId=222340885\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown"},{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-02-13T09:15:02.279407Z","iopub.execute_input":"2025-02-13T09:15:02.2798Z","iopub.status.idle":"2025-02-13T09:15:02.28767Z","shell.execute_reply.started":"2025-02-13T09:15:02.279768Z","shell.execute_reply":"2025-02-13T09:15:02.286512Z"}},"outputs":[{"name":"stdout","text":"/kaggle/input/playground-series-s5e2/sample_submission.csv\n/kaggle/input/playground-series-s5e2/train.csv\n/kaggle/input/playground-series-s5e2/test.csv\n/kaggle/input/playground-series-s5e2/training_extra.csv\n","output_type":"stream"}],"execution_count":7},{"cell_type":"code","source":"import pandas as pd\nfrom sklearn.model_selection import train_test_split, cross_val_score, KFold\nfrom sklearn.preprocessing import OneHotEncoder, MinMaxScaler\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\nimport numpy as np\nimport warnings","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-13T09:15:02.289077Z","iopub.execute_input":"2025-02-13T09:15:02.289383Z","iopub.status.idle":"2025-02-13T09:15:02.303361Z","shell.execute_reply.started":"2025-02-13T09:15:02.289348Z","shell.execute_reply":"2025-02-13T09:15:02.302681Z"}},"outputs":[],"execution_count":8},{"cell_type":"code","source":"warnings.filterwarnings(\"ignore\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-13T09:15:02.304921Z","iopub.execute_input":"2025-02-13T09:15:02.305122Z","iopub.status.idle":"2025-02-13T09:15:02.324201Z","shell.execute_reply.started":"2025-02-13T09:15:02.305105Z","shell.execute_reply":"2025-02-13T09:15:02.323394Z"}},"outputs":[],"execution_count":9},{"cell_type":"code","source":"train = pd.read_csv(\"/kaggle/input/playground-series-s5e2/train.csv\")\ntrain_extra = pd.read_csv(\"/kaggle/input/playground-series-s5e2/training_extra.csv\")\ntrain_data = pd.concat([train, train_extra], axis=0, ignore_index=True)\n\ntest_data = pd.read_csv(\"/kaggle/input/playground-series-s5e2/test.csv\")\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-13T09:15:02.325285Z","iopub.execute_input":"2025-02-13T09:15:02.325528Z","iopub.status.idle":"2025-02-13T09:15:08.27331Z","shell.execute_reply.started":"2025-02-13T09:15:02.325483Z","shell.execute_reply":"2025-02-13T09:15:08.272508Z"}},"outputs":[],"execution_count":10},{"cell_type":"code","source":"# Encode categorical features\ncategorical_features = ['Brand', 'Material', 'Size', 'Style', 'Color']\nencoder = OneHotEncoder(sparse_output=False, handle_unknown='ignore')\ncategorical_encoded = encoder.fit_transform(train_data[categorical_features])\ncategorical_data = pd.DataFrame(categorical_encoded, index=train_data.index, columns=encoder.get_feature_names_out(categorical_features))\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-13T09:15:08.274199Z","iopub.execute_input":"2025-02-13T09:15:08.274432Z","iopub.status.idle":"2025-02-13T09:15:14.708267Z","shell.execute_reply.started":"2025-02-13T09:15:08.274412Z","shell.execute_reply":"2025-02-13T09:15:14.707564Z"}},"outputs":[],"execution_count":11},{"cell_type":"markdown","source":"****Feature Extraction****","metadata":{}},{"cell_type":"code","source":"# Encode categorical features for test data\ncategorical_encoded_test = encoder.fit_transform(test_data[categorical_features])\ncategorical_data_test = pd.DataFrame(categorical_encoded_test, columns=encoder.get_feature_names_out(categorical_features))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-13T09:15:14.708928Z","iopub.execute_input":"2025-02-13T09:15:14.709137Z","iopub.status.idle":"2025-02-13T09:15:15.009561Z","shell.execute_reply.started":"2025-02-13T09:15:14.709119Z","shell.execute_reply":"2025-02-13T09:15:15.008793Z"}},"outputs":[],"execution_count":12},{"cell_type":"code","source":"numerical_features = ['id','Compartments', 'Weight Capacity (kg)']\nbinary_features = ['Laptop Compartment', 'Waterproof']\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-13T09:15:15.010379Z","iopub.execute_input":"2025-02-13T09:15:15.010599Z","iopub.status.idle":"2025-02-13T09:15:15.014292Z","shell.execute_reply.started":"2025-02-13T09:15:15.010581Z","shell.execute_reply":"2025-02-13T09:15:15.013372Z"}},"outputs":[],"execution_count":13},{"cell_type":"code","source":"train_data[binary_features] = train_data[binary_features].replace({'Yes': 1, 'No': 0})\ntest_data[binary_features] = test_data[binary_features].replace({'Yes': 1, 'No': 0})\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-13T09:15:15.015007Z","iopub.execute_input":"2025-02-13T09:15:15.015258Z","iopub.status.idle":"2025-02-13T09:15:18.065371Z","shell.execute_reply.started":"2025-02-13T09:15:15.015227Z","shell.execute_reply":"2025-02-13T09:15:18.064521Z"}},"outputs":[],"execution_count":14},{"cell_type":"code","source":"X_train = pd.concat([train_data[numerical_features + binary_features], categorical_data], axis=1)\nY_train = train_data[[\"Price\"]]\nX_test = pd.concat([test_data[numerical_features + binary_features], categorical_data_test], axis=1)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-13T09:15:18.068215Z","iopub.execute_input":"2025-02-13T09:15:18.068465Z","iopub.status.idle":"2025-02-13T09:15:19.94289Z","shell.execute_reply.started":"2025-02-13T09:15:18.068444Z","shell.execute_reply":"2025-02-13T09:15:19.942179Z"}},"outputs":[],"execution_count":15},{"cell_type":"code","source":"display(X_train)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"X_train.drop('id', axis =1)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"****Feature Scaling****","metadata":{}},{"cell_type":"code","source":"scaler = MinMaxScaler()\nX_train = scaler.fit_transform(X_train)\nX_test = scaler.fit_transform(X_test)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import pandas as pd\nfrom sklearn.impute import KNNImputer\nfrom concurrent.futures import ProcessPoolExecutor\n\n# Function to apply KNNImputer to a chunk of data\ndef impute_chunk(chunk):\n    imputer = KNNImputer(n_neighbors=5)\n    return imputer.fit_transform(chunk)\n\n# Define the number of chunks based on your system's CPU count\nnum_chunks = os.cpu_count()\n\n# Split the DataFrame into chunks\nchunks = np.array_split(X_train, num_chunks-1)\n\n# Use ProcessPoolExecutor to impute chunks in parallel\nwith ProcessPoolExecutor(max_workers=num_chunks) as executor:\n    results = executor.map(impute_chunk, chunks)\n\n# Combine the imputed chunks back into a single DataFrame\nX_train = pd.concat([pd.DataFrame(result) for result in results], ignore_index=True)\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Ensure your data is in NumPy array format\nX_train = X_train.to_numpy() if hasattr(X_train, 'to_numpy') else X_train\nY_train = Y_train.to_numpy() if hasattr(Y_train, 'to_numpy') else Y_train\nX_test = X_test.to_numpy() if hasattr(X_test, 'to_numpy') else X_test\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"**Random Forrest Initialization**","metadata":{}},{"cell_type":"code","source":"import tensorflow as tf\nprint(\"Num GPUs Available: \", len(tf.config.experimental.list_physical_devices('GPU')))","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import tensorflow as tf\n\n# Initialize the MirroredStrategy\nstrategy = tf.distribute.MirroredStrategy()\n\nprint(f\"Number of devices: {strategy.num_replicas_in_sync}\")\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"with strategy.scope():\n    model = RandomForestRegressor(\n            n_estimators=100,            # Number of trees in the forest\n            max_depth=None,              # Maximum depth of the tree (None allows full depth)\n            min_samples_split=2,         # Minimum samples required to split an internal node\n            min_samples_leaf=1,          # Minimum samples required to be a leaf node\n            max_features='sqrt',         # Number of features to consider when looking for the best split\n            bootstrap=True,              # Whether bootstrap samples are used when building trees\n            random_state=42             # Random state for reproducibility\n        \n        )","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from sklearn.ensemble import RandomForestRegressor\nfrom sklearn.model_selection import KFold\n\n\n# Perform K-fold cross-validation\nkf = KFold(n_splits=5, shuffle=True, random_state=42)\nfold_no = 1\nscores = []\n\nfor train_index, val_index in kf.split(X_train):\n    # Split the data\n    X_train_fold, X_val_fold = X_train[train_index], X_train[val_index]\n    Y_train_fold, Y_val_fold = Y_train[train_index], Y_train[val_index]\n\n    # Train the model\n    model.fit(X_train_fold, Y_train_fold)\n\n    # Evaluate the model\n    score = model.score(X_val_fold, Y_val_fold)\n    print(f\"Fold {fold_no} - R2 Score: {score:.4f}\")\n    scores.append(score)\n\n    fold_no += 1\n\n# Average score across folds\nprint(f\"Average R2 Score: {sum(scores) / len(scores):.4f}\")\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"model.predict(X_test)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}